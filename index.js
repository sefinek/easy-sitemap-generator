const { JSDOM } = require('jsdom');
const { axios, version } = require('./services/axios.js');
const urlModule = require('url');
const fs = require('fs');
const path = require('path');
const { escapeXml, normalizeUrl, calculatePriority } = require('./utils/xml.js');
const { logInfo, logSuccess, logError, logWarning } = require('./utils/kleur.js');

const args = process.argv.slice(2);
const urlArg = args.find(arg => arg.startsWith('--domain='));
if (!urlArg) {
	logError('No URL provided. Use: node . --domain=<YOUR-DOMAIN>');
	process.exit(1);
}

const BASE_URL = `https://${urlArg.split('=')[1].replace(/(^\w+:|^)\/\//, '')}`;
const VISITED_URLS = new Set();
const IGNORED_PATTERNS = ['cdn-cgi', '?referrer=', '&referrer='];
const BASE_DELAY = 7000;

const shouldIncludeUrl = (url, baseUrl) => !IGNORED_PATTERNS.some(pattern => url.includes(pattern)) && url.startsWith(baseUrl);
const delay = ms => new Promise(resolve => setTimeout(resolve, ms));

const fetchUrl = async (url, retries = 0) => {
	try {
		logInfo(`GET ${url}`);
		return await axios.get(url);
	} catch (error) {
		if (error.response) {
			const statusCode = error.response.status;
			if (statusCode === 429) {
				const delayTime = BASE_DELAY * Math.pow(2, retries);
				logWarning(`Rate limit hit. Retrying in ${(delayTime / 1000).toFixed(2)}s... (Attempt ${retries + 1})`);
				await delay(delayTime);
				return fetchUrl(url, retries + 1);
			} else if (statusCode >= 500) {
				logError(`Failed to fetch ${url}. Status code: ${statusCode}. Skipping...`);
				return null;
			} else if (statusCode >= 400) {
				logWarning(`Failed to fetch ${url}. Status code: ${statusCode}. Skipping...`);
				return null;
			}
		} else {
			logError(`Failed to fetch ${url}. Unknown error: ${error.message}. Skipping...`);
			return null;
		}
	}
};

const crawl = async url => {
	const normalizedUrl = normalizeUrl(url);
	if (VISITED_URLS.has(normalizedUrl)) return;

	VISITED_URLS.add(normalizedUrl);

	const response = await fetchUrl(normalizedUrl);
	if (!response) return;

	const { document } = new JSDOM(response.data).window;
	const links = Array.from(document.querySelectorAll('a[href]'))
		.map(link => urlModule.resolve(BASE_URL, link.getAttribute('href')))
		.map(normalizeUrl)
		.filter(link => shouldIncludeUrl(link, BASE_URL));

	for (const link of links) {
		await crawl(link);
	}

	return { url: normalizedUrl, lastmod: response.headers['last-modified'] ? new Date(response.headers['last-modified']).toISOString() : new Date().toISOString() };
};

(async () => {
	logInfo(`Starting crawl for base URL: ${BASE_URL}`);

	await crawl(BASE_URL);

	logInfo(`Generating sitemap with ${VISITED_URLS.size} URLs...`);

	const urls = Array.from(VISITED_URLS)
		.filter(url => shouldIncludeUrl(url, BASE_URL))
		.map(url => ({
			url,
			priority: calculatePriority(url, BASE_URL),
			lastmod: new Date().toISOString()
		}))
		.sort((a, b) => b.priority - a.priority);

	const sitemapContent = `<?xml version="1.0" encoding="UTF-8"?>
<!-- Generated by https://github.com/sefinek24/free-sitemap-generator (version ${version}) - ${new Date()} -->
<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:schemaLocation="http://www.sitemaps.org/schemas/sitemap/0.9 http://www.sitemaps.org/schemas/sitemap/0.9/sitemap.xsd">
${urls.map(({ url, priority, lastmod }) => `    <url>
        <loc>${escapeXml(url)}</loc>
        <lastmod>${lastmod}</lastmod>
        <priority>${priority.toFixed(2)}</priority>
    </url>`).join('\n')}
</urlset>`;

	const outputPath = path.resolve('sitemap.xml');
	fs.writeFileSync(outputPath, sitemapContent, 'utf8');
	logSuccess(`Sitemap has been generated at ${outputPath}`);
})();
